{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import matplotlib\n",
    "import re\n",
    "import pydot\n",
    "from graphviz import Digraph\n",
    "from graphviz import Source\n",
    "from utils import Utils\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('train-data.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from networkx.readwrite import json_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = tree.findall('instance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {}\n",
    "id_to_questions = defaultdict(list)\n",
    "id_to_answers = defaultdict(list)\n",
    "id_to_correct = defaultdict(list)\n",
    "id_to_type = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I process the data, read it into the above defined dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for inst in instances:\n",
    "    text = inst.find('text').text\n",
    "    texts[count] = text\n",
    "    questions = inst.find('questions').findall('question')\n",
    "    for q in questions:\n",
    "        id_to_questions[count].append(q.attrib['text'])\n",
    "        id_to_type[count].append(q.attrib['type'])\n",
    "        ans = q.findall('answer')\n",
    "        ans_text = []\n",
    "        corr_text = []\n",
    "        for a in ans:\n",
    "            ans_text.append(a.attrib['text'])\n",
    "            corr_text.append(a.attrib['correct'])\n",
    "        id_to_answers[count].append(ans_text)\n",
    "        id_to_correct[count].append(corr_text)\n",
    "    count+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now first I process the texts, so it doesnt need processing for every question.\n",
    "\n",
    "I defined two new endpoint:\n",
    "* rallyexp - In this endpoint, I process the question with an answer and construct a new graph from the two of them. It uses the definitions of the words.\n",
    "* rallyabs - Same as the rallyexp, only with the abstraction rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = Utils()\n",
    "text_edges = {}\n",
    "for j in texts.keys():\n",
    "    print(j)\n",
    "    data = {'sentence':   texts[j]}\n",
    "    data_json = json.dumps(data)\n",
    "    payload = {'json_payload': data_json}\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "    try:\n",
    "        r = requests.post(\"http://hlt.bme.hu/4lang/senexp\", data=data_json, headers=headers)\n",
    "        s_machines = r.json()['sentence']\n",
    "    except ValueError:\n",
    "        continue\n",
    "    g_sen = json_graph.adjacency.adjacency_graph(s_machines)\n",
    "\n",
    "    edges_text = utils.get_edges(g_sen)\n",
    "    text_edges[j] = edges_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I retrieve the text from the dict, after that I build two graphs with the two question-answer pairs and then calculate the\n",
    "edge similarities to the text's graphs. The more similar graph will be the True answer and the other will be False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = {}\n",
    "question2 = {}\n",
    "def get_pred(text, question, answers):   \n",
    "    edges_text = text_edges[text]\n",
    "    \n",
    "    data = {'question':   question, 'answer': answers[0]}\n",
    "    data_json = json.dumps(data)\n",
    "    payload = {'json_payload': data_json}\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "    r = requests.post(\"http://hlt.bme.hu/4lang/rallyexp\", data=data_json, headers=headers)\n",
    "    first_machines = r.json()['rally']\n",
    "    g_que1 = json_graph.adjacency.adjacency_graph(first_machines)\n",
    "    \n",
    "    edges_question1 = utils.get_edges(g_que1)\n",
    "    question1[text] = g_que1\n",
    "    \n",
    "    data = {'question':   question, 'answer': answers[1]}\n",
    "    data_json = json.dumps(data)\n",
    "    payload = {'json_payload': data_json}\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "    r = requests.post(\"http://hlt.bme.hu/4lang/rallyexp\", data=data_json, headers=headers)\n",
    "    second_machines = r.json()['rally']\n",
    "    g_que2 = json_graph.adjacency.adjacency_graph(second_machines)\n",
    "        \n",
    "    question2[text] = g_que2\n",
    "    edges_question2 = utils.get_edges(g_que2)\n",
    "    \n",
    "    sim_to_first = utils.asim_jac(edges_text, edges_question1)\n",
    "    sim_to_second = utils.asim_jac(edges_text, edges_question2)\n",
    "    return ['True', 'False'] if sim_to_first >= sim_to_second else ['False', 'True']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I iterate over the dataset, and run the above defined method only with questions that are not commonsense, and only if there are a question word in the question. I close out one worded answers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = 0\n",
    "all_q = 0 \n",
    "qst_words = [\"why\", \"where\", \"how\", \"when\", \"what\", \"who\"]\n",
    "correct = []\n",
    "pred = []\n",
    "for i in texts.keys():\n",
    "    for quest, typ, corr, ans in zip(id_to_questions[i], id_to_type[i], id_to_correct[i], id_to_answers[i]):\n",
    "        all_q += 1\n",
    "        right_q = [i for i in qst_words if i in quest.lower()]\n",
    "        if len(right_q) > 0 and typ == 'text':\n",
    "            try:\n",
    "                prediction = get_pred(i, quest, ans)\n",
    "            except:\n",
    "                continue\n",
    "            correct.append(int(corr[0] == 'True'))\n",
    "            correct.append(int(corr[1] == 'True'))\n",
    "            pred.append(int(prediction[0] == 'True'))\n",
    "            pred.append(int(prediction[1] == 'True'))\n",
    "            print(right)\n",
    "            right+=1\n",
    "print(right)\n",
    "print(all_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(correct, pred)\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(correct, pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6837200456447319\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is the same as above, only using the abstraction endpoint with expanded text graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_edges_abstract = {}\n",
    "text_abstract = {}\n",
    "for j in texts.keys():\n",
    "    print(j)        \n",
    "    data = {'sentence':   texts[j]}\n",
    "    data_json = json.dumps(data)\n",
    "    payload = {'json_payload': data_json}\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "    try:\n",
    "        r = requests.post(\"http://hlt.bme.hu/4lang/senabs\", data=data_json, headers=headers)\n",
    "        s_machines = r.json()['sentence']\n",
    "    except ValueError:\n",
    "        continue\n",
    "    g_sen = json_graph.adjacency.adjacency_graph(s_machines)\n",
    "\n",
    "    edges_text = utils.get_edges(g_sen)\n",
    "    text_edges_abstract[j] = edges_text\n",
    "    text_abstract[j] = g_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_abs(text, question, answers):   \n",
    "    edges_text = text_edges[text]\n",
    "    \n",
    "    data = {'question':   question, 'answer': answers[0]}\n",
    "    data_json = json.dumps(data)\n",
    "    payload = {'json_payload': data_json}\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "    r = requests.post(\"http://hlt.bme.hu/4lang/rallyabs\", data=data_json, headers=headers)\n",
    "    first_machines = r.json()['rally']\n",
    "    g_que1 = json_graph.adjacency.adjacency_graph(first_machines)\n",
    "    \n",
    "    edges_question1 = utils.get_edges(g_que1)\n",
    "    question1[text] = g_que1\n",
    "    \n",
    "    data = {'question':   question, 'answer': answers[1]}\n",
    "    data_json = json.dumps(data)\n",
    "    payload = {'json_payload': data_json}\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "    r = requests.post(\"http://hlt.bme.hu/4lang/rallyabs\", data=data_json, headers=headers)\n",
    "    second_machines = r.json()['rally']\n",
    "    g_que2 = json_graph.adjacency.adjacency_graph(second_machines)\n",
    "        \n",
    "    question2[text] = g_que2\n",
    "    edges_question2 = utils.get_edges(g_que2)\n",
    "    \n",
    "    sim_to_first = utils.asim_jac(edges_text, edges_question1)\n",
    "    sim_to_second = utils.asim_jac(edges_text, edges_question2)\n",
    "    return ['True', 'False'] if sim_to_first >= sim_to_second else ['False', 'True']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = 0\n",
    "all_q = 0 \n",
    "qst_words = [\"why\", \"where\", \"how\", \"when\", \"what\", \"who\"]\n",
    "correct = []\n",
    "pred = []\n",
    "for i in texts.keys():\n",
    "    for quest, typ, corr, ans in zip(id_to_questions[i], id_to_type[i], id_to_correct[i], id_to_answers[i]):\n",
    "        all_q += 1\n",
    "        right_q = [i for i in qst_words if i in quest.lower()]\n",
    "        if len(right_q) > 0 and typ == 'text':\n",
    "            try:\n",
    "                prediction = get_pred_abs(i, quest, ans)\n",
    "            except:\n",
    "                continue\n",
    "            correct.append(int(corr[0] == 'True'))\n",
    "            correct.append(int(corr[1] == 'True'))\n",
    "            pred.append(int(prediction[0] == 'True'))\n",
    "            pred.append(int(prediction[1] == 'True'))\n",
    "            print(right)\n",
    "            right+=1\n",
    "print(right)\n",
    "print(all_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(correct, pred)\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(correct, pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5812095853936858\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_varied(text, question, answers, edge_type, ans_type):\n",
    "    if edge_type == 0:\n",
    "        edges_text = text_edges_abstract[text]\n",
    "    elif edge_type == 1:\n",
    "        edges_text = text_edges[text]\n",
    "    \n",
    "    if ans_type == 0:        \n",
    "        data = {'question':   question, 'answer': answers[0]}\n",
    "        data_json = json.dumps(data)\n",
    "        payload = {'json_payload': data_json}\n",
    "        headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "        r = requests.post(\"http://hlt.bme.hu/4lang/rallyabs\", data=data_json, headers=headers)\n",
    "        first_machines = r.json()['rally']\n",
    "        g_que1 = json_graph.adjacency.adjacency_graph(first_machines)\n",
    "\n",
    "        edges_question1 = utils.get_edges(g_que1)\n",
    "        question1[text] = g_que1\n",
    "\n",
    "        data = {'question':   question, 'answer': answers[1]}\n",
    "        data_json = json.dumps(data)\n",
    "        payload = {'json_payload': data_json}\n",
    "        headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "        r = requests.post(\"http://hlt.bme.hu/4lang/rallyabs\", data=data_json, headers=headers)\n",
    "        second_machines = r.json()['rally']\n",
    "        g_que2 = json_graph.adjacency.adjacency_graph(second_machines)\n",
    "\n",
    "        question2[text] = g_que2\n",
    "        edges_question2 = utils.get_edges(g_que2)\n",
    "    elif ans_type == 1:\n",
    "        data = {'question':   question, 'answer': answers[0]}\n",
    "        data_json = json.dumps(data)\n",
    "        payload = {'json_payload': data_json}\n",
    "        headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "        r = requests.post(\"http://hlt.bme.hu/4lang/rallyexp\", data=data_json, headers=headers)\n",
    "        first_machines = r.json()['rally']\n",
    "        g_que1 = json_graph.adjacency.adjacency_graph(first_machines)\n",
    "\n",
    "        edges_question1 = utils.get_edges(g_que1)\n",
    "        question1[text] = g_que1\n",
    "\n",
    "        data = {'question':   question, 'answer': answers[1]}\n",
    "        data_json = json.dumps(data)\n",
    "        payload = {'json_payload': data_json}\n",
    "        headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "        r = requests.post(\"http://hlt.bme.hu/4lang/rallyexp\", data=data_json, headers=headers)\n",
    "        second_machines = r.json()['rally']\n",
    "        g_que2 = json_graph.adjacency.adjacency_graph(second_machines)\n",
    "\n",
    "        question2[text] = g_que2\n",
    "        edges_question2 = utils.get_edges(g_que2)\n",
    "    \n",
    "    sim_to_first = utils.asim_jac(edges_text, edges_question1)\n",
    "    sim_to_second = utils.asim_jac(edges_text, edges_question2)\n",
    "    return ['True', 'False'] if sim_to_first >= sim_to_second else ['False', 'True']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = 0\n",
    "all_q = 0 \n",
    "qst_words = [\"why\", \"where\", \"how\", \"when\", \"what\", \"who\"]\n",
    "correct = []\n",
    "pred = []\n",
    "for i in texts.keys():\n",
    "    for quest, typ, corr, ans in zip(id_to_questions[i], id_to_type[i], id_to_correct[i], id_to_answers[i]):\n",
    "        all_q += 1\n",
    "        right_q = [i for i in qst_words if i in quest.lower()]\n",
    "        if len(right_q) > 0 and typ == 'text':\n",
    "            try:\n",
    "                prediction = get_pred_varied(i, quest, ans, 0, 0)\n",
    "            except:\n",
    "                continue\n",
    "            correct.append(int(corr[0] == 'True'))\n",
    "            correct.append(int(corr[1] == 'True'))\n",
    "            pred.append(int(prediction[0] == 'True'))\n",
    "            pred.append(int(prediction[1] == 'True'))\n",
    "            print(right)\n",
    "            right+=1\n",
    "print(right)\n",
    "print(all_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6610233973749287"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(correct, pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = 0\n",
    "all_q = 0 \n",
    "qst_words = [\"why\", \"where\", \"how\", \"when\", \"what\", \"who\"]\n",
    "correct = []\n",
    "pred = []\n",
    "for i in texts.keys():\n",
    "    for quest, typ, corr, ans in zip(id_to_questions[i], id_to_type[i], id_to_correct[i], id_to_answers[i]):\n",
    "        all_q += 1\n",
    "        right_q = [i for i in qst_words if i in quest.lower()]\n",
    "        if len(right_q) > 0 and typ == 'text':\n",
    "            try:\n",
    "                prediction = get_pred_varied(i, quest, ans, 0, 1)\n",
    "            except:\n",
    "                continue\n",
    "            correct.append(int(corr[0] == 'True'))\n",
    "            correct.append(int(corr[1] == 'True'))\n",
    "            pred.append(int(prediction[0] == 'True'))\n",
    "            pred.append(int(prediction[1] == 'True'))\n",
    "            print(right)\n",
    "            right+=1\n",
    "print(right)\n",
    "print(all_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5722708254089007"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(correct, pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
